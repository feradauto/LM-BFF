{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ddf940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Finetuning the library models for sequence classification on GLUE.\"\"\"\n",
    "\n",
    "import dataclasses\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, Optional\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, EvalPrediction\n",
    "from transformers import GlueDataTrainingArguments as DataTrainingArguments\n",
    "from transformers import HfArgumentParser, TrainingArguments, set_seed\n",
    "\n",
    "from src.dataset import FewShotDataset\n",
    "from src.models import BertForPromptFinetuning, RobertaForPromptFinetuning, resize_token_type_embeddings\n",
    "from src.trainer import Trainer\n",
    "from src.processors import processors_mapping, num_labels_mapping, output_modes_mapping, compute_metrics_mapping, bound_mapping\n",
    "\n",
    "from filelock import FileLock\n",
    "from datetime import datetime\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5da5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
    "    \"\"\"\n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
    "    )\n",
    "    # Few-shot type\n",
    "    #   - finetune: standard fine-tuning\n",
    "    #   - prompt: prompt-based fine-tuning\n",
    "    #   - prompt-demo: prompt-based fine-tuning with demonstrations\n",
    "    few_shot_type: str = field(\n",
    "        default='prompt-demo',\n",
    "        metadata={\"help\": \"Few-shot learning model type. Choice: finetune, prompt, prompt-demo\"}\n",
    "    )\n",
    "\n",
    "    # Only for BERT-type model\n",
    "    random_segment: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to reinitialize the token type embeddings (only for BERT).\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class DynamicDataTrainingArguments(DataTrainingArguments):\n",
    "    \"\"\"\n",
    "    Arguments for dynamic training.\n",
    "    \"\"\"\n",
    "    num_k: Optional[int] = field(\n",
    "        default=16,\n",
    "        metadata={\"help\": \"Number of training instances per class\"}\n",
    "    )\n",
    "\n",
    "    num_sample: Optional[int] = field(\n",
    "        default=16,\n",
    "        metadata={\"help\": \"Number of samples (for inference) in fine-tuning with demonstrations\"}\n",
    "    )\n",
    "\n",
    "    num_demo: Optional[int] = field(\n",
    "        default=1,\n",
    "        metadata={\"help\": \"Number of demonstrations from each class\"}\n",
    "    )\n",
    "\n",
    "    auto_demo: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Automatically generate template for using demonstrations\"}\n",
    "    )\n",
    "\n",
    "    # For prompting\n",
    "    template: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Template\"}\n",
    "    )\n",
    "\n",
    "    mapping: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Label word mapping\"}\n",
    "    )\n",
    "\n",
    "    template_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to a txt file that stores all the templates, one per line. Do not set this when prompt_path is used\"}\n",
    "    )\n",
    "\n",
    "    mapping_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to a txt file that stores all the label word mappings, one per line. Do not set this when prompt_path is used\"}\n",
    "    )\n",
    "\n",
    "    prompt_path: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to a txt file that stores all the prompts (templates and mappings), one per line\"}\n",
    "    )\n",
    " \n",
    "    template_id: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Template id if using template_path\"}\n",
    "    )\n",
    "\n",
    "    mapping_id: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Mapping id if using template_path\"}\n",
    "    )\n",
    "\n",
    "    prompt_id: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Prompt id if using prompt_path\"}\n",
    "    )\n",
    "\n",
    "    top_n_template: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Use top-n template in the template path\"}\n",
    "    )\n",
    "\n",
    "    # For logging\n",
    "    tag: str = field(\n",
    "        default='',\n",
    "        metadata={\"help\": \"Set the tag and find the result easier in the log.\"}\n",
    "    )\n",
    "\n",
    "    # For filtering when using demonstrations\n",
    "    demo_filter: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Only use similar instances in demonstrations\"}\n",
    "    )\n",
    "\n",
    "    demo_filter_rate: float = field(\n",
    "        default=0.5,\n",
    "        metadata={\"help\": \"Only use top-x\\% similar instances in demonstrations\"}\n",
    "    )\n",
    "\n",
    "    demo_filter_model: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Model name for demonstration filter embeddings. Will load embeddings based on the model name.\"}\n",
    "    )\n",
    "\n",
    "    debug_mode: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Debug mode\"}\n",
    "    )\n",
    "\n",
    "    # For max length\n",
    "    double_demo: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Use double length for using demonstrations\"}\n",
    "    )\n",
    "\n",
    "    first_sent_limit: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Limit the length of the first sentence (i.e., sent_0)\"}\n",
    "    )\n",
    "\n",
    "    other_sent_limit: int = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Limit the length of sentences other than the first sentence\"}\n",
    "    )\n",
    "\n",
    "    use_full_length: bool = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Use the full length (512)\"}\n",
    "    )\n",
    "\n",
    "    # GPT-3's in-context learning\n",
    "    gpt3_in_context_head: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"GPT-3's in-context learning (context at the beginning)\"}\n",
    "    )\n",
    "\n",
    "    gpt3_in_context_tail: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"GPT-3's in-context learning (context at the end)\"}\n",
    "    )\n",
    "\n",
    "    gpt3_in_context_num: int = field(\n",
    "        default=32,\n",
    "        metadata={\"help\": \"Number of context examples\"}\n",
    "    )\n",
    "\n",
    "    truncate_head: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"When exceeding the maximum length, truncate the head instead of the tail.\"}\n",
    "    )\n",
    "\n",
    "    # Do not set up the following fields. They are set up automatically.\n",
    "    prompt: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Whether to use prompt-based fine-tuning\"}\n",
    "    )\n",
    "    template_list: list = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"(DO NOT List of templates (only initialized after the program starts.\"}\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DynamicTrainingArguments(TrainingArguments):\n",
    "    # For ensemble\n",
    "    array_id: int = field(\n",
    "        default=-1,\n",
    "        metadata={\"help\": \"Array ID (contains seed and hyper-paramter search) to idenfity the model\"}\n",
    "    )\n",
    "\n",
    "    model_id: int = field(\n",
    "        default=-1,\n",
    "        metadata={\"help\": \"Model ID (contains template information) to identify the model\"}\n",
    "    )\n",
    "\n",
    "    save_logit: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Save test file logit with name $TASK-$MODEL_ID-$ARRAY_ID.npy\"}\n",
    "    )\n",
    "\n",
    "    save_logit_dir: str = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where to save the prediction result\"}\n",
    "    )\n",
    "\n",
    "    # Regularization\n",
    "    fix_layers: int = field(\n",
    "        default=0,\n",
    "        metadata={\"help\": \"Fix bottom-n layers when optimizing\"}\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    save_at_last: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Instead of saving the best (dev performance) checkpoint, save the last checkpoint\"}\n",
    "    )\n",
    "\n",
    "    # Turn off train/test\n",
    "    no_train: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"No training\"}\n",
    "    )\n",
    "    no_predict: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"No test\"}\n",
    "    )\n",
    "    evaluate_during_training: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"evaluate_during_training\"}\n",
    "    )   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1058e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86faf914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/ipykernel_launcher.py',\n",
       " '-f',\n",
       " '/cluster/home/fgonzalez/.local/share/jupyter/runtime/kernel-b2f2dd87-4a5e-46a9-908b-40dc54c93546.json',\n",
       " '--model_name_or_path',\n",
       " 'path',\n",
       " 'task_name',\n",
       " 'path1',\n",
       " 'data_dir',\n",
       " 'path2',\n",
       " 'output_dir',\n",
       " 'path3']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "159fc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.append(\"--task_name\")\n",
    "sys.argv.append(\"papers\")\n",
    "sys.argv.append(\"--data_dir\")\n",
    "sys.argv.append(\"/cluster/scratch/fgonzalez/auto_template/papers/16-42\")\n",
    "sys.argv.append(\"--overwrite_output_dir\")\n",
    "sys.argv.append(\"--do_train\")\n",
    "sys.argv.append(\"--do_eval\")\n",
    "sys.argv.append(\"--do_predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc60b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "--task_name, --data_dir, --output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e3dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  --overwrite_output_dir \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --do_predict \\\n",
    "  --evaluate_during_training \\\n",
    "  --model_name_or_path $MODEL \\\n",
    "  --few_shot_type $TYPE \\\n",
    "  --num_k $K \\\n",
    "  --max_seq_length 128 \\\n",
    "  --per_device_train_batch_size $REAL_BS \\\n",
    "  --per_device_eval_batch_size 16 \\\n",
    "  --gradient_accumulation_steps $GS \\\n",
    "  --learning_rate $LR \\\n",
    "  --max_steps $MAX_STEP \\\n",
    "  --logging_steps $EVAL_STEP \\\n",
    "  --eval_steps $EVAL_STEP \\\n",
    "  --num_train_epochs 0 \\\n",
    "  --output_dir result/$TASK-$TYPE-$K-$SEED-$MODEL-$TRIAL_IDTF \\\n",
    "  --seed $SEED \\\n",
    "  --tag $TAG \\\n",
    "  --template $TEMPLATE \\\n",
    "  --mapping $MAPPING \\\n",
    "  $TASK_EXTRA \\\n",
    "  $1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d8ed4451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./log\") as f:\n",
    "    result_list = []\n",
    "    for line in f:\n",
    "        line=line.replace(\"device(type=\\'cuda\\', index=0)\",\"\\\"cuda:0\\\"\")\n",
    "        line=line.replace(\"<SchedulerType.LINEAR: \\'linear\\'>\",\"\\\"linear\\\"\")\n",
    "        line=line.replace(\"<IntervalStrategy.STEPS: \\'steps\\'>\",\"\\\"steps\\\"\")\n",
    "        result_list.append(eval(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09691982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time': '2022-03-30 21:26:05.012539',\n",
       "  'sst-2_dev_eval_loss': 0.23619166016578674,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-4688',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-4688/runs/Mar30_21-16-13_eu-lo-dgx1-001',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-4688',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-4688',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_It's*mask*.*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 0,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 21:36:25.835493',\n",
       "  'sst-2_dev_eval_loss': 0.22473298013210297,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-26504',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-26504/runs/Mar30_21-26-53_eu-lo-dgx1-001',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-26504',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-26504',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 1,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 22:58:41.112672',\n",
       "  'sst-2_dev_eval_loss': 0.2508125603199005,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12083',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12083/runs/Mar30_22-52-18_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12083',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12083',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_It's*mask*.*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 0,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:05:12.949744',\n",
       "  'sst-2_dev_eval_loss': 0.24416212737560272,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-31956',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-31956/runs/Mar30_22-58-49_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-31956',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-31956',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 1,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:11:31.753294',\n",
       "  'sst-2_dev_eval_loss': 0.21178890764713287,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-2209',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-2209/runs/Mar30_23-05-24_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-2209',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-2209',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_This_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 2,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:17:53.720809',\n",
       "  'sst-2_dev_eval_loss': 0.2519993484020233,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-23988',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-23988/runs/Mar30_23-11-39_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-23988',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-23988',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_It's*mask*!*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 3,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:24:21.656225',\n",
       "  'sst-2_dev_eval_loss': 0.23626796901226044,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-16821',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-16821/runs/Mar30_23-18-01_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-16821',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-16821',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_movie.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 4,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:30:50.963428',\n",
       "  'sst-2_dev_eval_loss': 0.25055742263793945,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-8269',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-8269/runs/Mar30_23-24-30_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-8269',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-8269',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_film.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 5,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:37:18.265397',\n",
       "  'sst-2_dev_eval_loss': 0.22665870189666748,\n",
       "  'sst-2_dev_eval_acc': 0.9621559633027523,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-28915',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-28915/runs/Mar30_23-30-58_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-28915',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-28915',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_was*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 6,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:43:51.888263',\n",
       "  'sst-2_dev_eval_loss': 0.2611183822154999,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-8209',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-8209/runs/Mar30_23-37-26_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-8209',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-8209',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Very*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 7,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:50:12.224843',\n",
       "  'sst-2_dev_eval_loss': 0.3155285120010376,\n",
       "  'sst-2_dev_eval_acc': 0.9506880733944955,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-30349',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-30349/runs/Mar30_23-43-59_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-30349',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-30349',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_This_is*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 8,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-30 23:56:34.961493',\n",
       "  'sst-2_dev_eval_loss': 0.23361776769161224,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-15978',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-15978/runs/Mar30_23-50-20_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-15978',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-15978',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Its*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 9,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:02:58.511525',\n",
       "  'sst-2_dev_eval_loss': 0.2562973201274872,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-5482',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-5482/runs/Mar30_23-56-42_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-5482',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-5482',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_is*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 10,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:09:26.024712',\n",
       "  'sst-2_dev_eval_loss': 0.2677866518497467,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-897',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-897/runs/Mar31_00-03-06_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-897',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-897',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Just*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 11,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:15:42.330387',\n",
       "  'sst-2_dev_eval_loss': 0.2690170407295227,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-26032',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-26032/runs/Mar31_00-09-33_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-26032',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-26032',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_story.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 12,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:21:55.698888',\n",
       "  'sst-2_dev_eval_loss': 0.22428981959819794,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-30183',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-30183/runs/Mar31_00-15-49_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-30183',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-30183',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Really*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 13,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:28:26.235617',\n",
       "  'sst-2_dev_eval_loss': 0.22115255892276764,\n",
       "  'sst-2_dev_eval_acc': 0.9610091743119266,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12131',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12131/runs/Mar31_00-22-03_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12131',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12131',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_That's*mask*.*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 14,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:34:53.643882',\n",
       "  'sst-2_dev_eval_loss': 0.28225401043891907,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-31317',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-31317/runs/Mar31_00-28-34_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-31317',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-31317',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It’s*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 15,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:41:31.747999',\n",
       "  'sst-2_dev_eval_loss': 0.2591903805732727,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-31693',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-31693/runs/Mar31_00-35-01_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-31693',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-31693',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*.*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 16,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:48:20.369066',\n",
       "  'sst-2_dev_eval_loss': 0.221043199300766,\n",
       "  'sst-2_dev_eval_acc': 0.9621559633027523,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-19203',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-19203/runs/Mar31_00-41-39_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-19203',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-19203',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_So*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 17,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 00:54:47.707894',\n",
       "  'sst-2_dev_eval_loss': 0.24847255647182465,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-16255',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-16255/runs/Mar31_00-48-27_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-16255',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-16255',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Absolutely*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 18,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:01:10.785092',\n",
       "  'sst-2_dev_eval_loss': 0.21322447061538696,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12225',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12225/runs/Mar31_00-54-55_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12225',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12225',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Looks*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 19,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:07:41.501715',\n",
       "  'sst-2_dev_eval_loss': 0.1791982799768448,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-17802',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-17802/runs/Mar31_01-01-18_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-17802',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-17802',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_looks*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 20,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:14:05.827083',\n",
       "  'sst-2_dev_eval_loss': 0.2099761962890625,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-30395',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-30395/runs/Mar31_01-07-49_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-30395',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-30395',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_read.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 21,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:20:36.917861',\n",
       "  'sst-2_dev_eval_loss': 0.20132088661193848,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-532',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-532/runs/Mar31_01-14-12_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-532',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-532',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_movie!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 22,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:27:02.412997',\n",
       "  'sst-2_dev_eval_loss': 0.23467326164245605,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-4785',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-4785/runs/Mar31_01-20-47_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-4785',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-4785',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*.*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 23,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:33:26.847135',\n",
       "  'sst-2_dev_eval_loss': 0.2641955018043518,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-29197',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-29197/runs/Mar31_01-27-10_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-29197',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-29197',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Very*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 24,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:39:45.676098',\n",
       "  'sst-2_dev_eval_loss': 0.24586865305900574,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-3583',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-3583/runs/Mar31_01-33-35_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-3583',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-3583',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_It_was*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 25,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:46:02.426710',\n",
       "  'sst-2_dev_eval_loss': 0.2124486267566681,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-24019',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-24019/runs/Mar31_01-39-52_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-24019',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-24019',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_film!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 26,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:52:29.248455',\n",
       "  'sst-2_dev_eval_loss': 0.2331986427307129,\n",
       "  'sst-2_dev_eval_acc': 0.9621559633027523,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-9221',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-9221/runs/Mar31_01-46-10_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-9221',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-9221',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_experience.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 27,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 01:58:48.328022',\n",
       "  'sst-2_dev_eval_loss': 0.23383666574954987,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-18965',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-18965/runs/Mar31_01-52-36_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-18965',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-18965',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_The_film_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 28,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:05:17.451436',\n",
       "  'sst-2_dev_eval_loss': 0.22581157088279724,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-11337',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-11337/runs/Mar31_01-58-55_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-11337',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-11337',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Sounds*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 29,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:11:57.480275',\n",
       "  'sst-2_dev_eval_loss': 0.27530637383461,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-2664',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-2664/runs/Mar31_02-05-27_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-2664',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-2664',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_So*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 30,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:18:31.220893',\n",
       "  'sst-2_dev_eval_loss': 0.23363833129405975,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12942',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12942/runs/Mar31_02-12-04_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12942',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12942',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_That_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 31,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:25:04.795745',\n",
       "  'sst-2_dev_eval_loss': 0.21407029032707214,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-451',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-451/runs/Mar31_02-18-37_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-451',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-451',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_It's_just*mask*.*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 32,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:31:46.463736',\n",
       "  'sst-2_dev_eval_loss': 0.2279297560453415,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-9634',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-9634/runs/Mar31_02-25-12_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-9634',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-9634',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_All*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 33,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:38:11.039215',\n",
       "  'sst-2_dev_eval_loss': 0.2665022015571594,\n",
       "  'sst-2_dev_eval_acc': 0.9506880733944955,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-27108',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-27108/runs/Mar31_02-31-53_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-27108',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-27108',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_it's*mask*.*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 34,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:44:44.489082',\n",
       "  'sst-2_dev_eval_loss': 0.2316371351480484,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-7989',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-7989/runs/Mar31_02-38-18_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-7989',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-7989',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_They_are*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 35,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:51:10.306831',\n",
       "  'sst-2_dev_eval_loss': 0.24913588166236877,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-24150',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-24150/runs/Mar31_02-44-51_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-24150',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-24150',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_The_movie_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 36,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 02:57:30.349556',\n",
       "  'sst-2_dev_eval_loss': 0.223220095038414,\n",
       "  'sst-2_dev_eval_acc': 0.9506880733944955,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-5825',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-5825/runs/Mar31_02-51-17_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-5825',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-5825',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls**sent_0*_That's*mask*!*sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 37,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:04:14.125103',\n",
       "  'sst-2_dev_eval_loss': 0.3095548152923584,\n",
       "  'sst-2_dev_eval_acc': 0.9518348623853211,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-11893',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-11893/runs/Mar31_02-57-37_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-11893',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-11893',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Not*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 38,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:10:38.560054',\n",
       "  'sst-2_dev_eval_loss': 0.2412727028131485,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12465',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12465/runs/Mar31_03-04-21_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12465',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12465',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Seems*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 39,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:16:58.812485',\n",
       "  'sst-2_dev_eval_loss': 0.23440107703208923,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-6665',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-6665/runs/Mar31_03-10-45_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-6665',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-6665',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_one.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 40,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:23:22.687008',\n",
       "  'sst-2_dev_eval_loss': 0.23221410810947418,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-30670',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-30670/runs/Mar31_03-17-06_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-30670',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-30670',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_This_was*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 41,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:29:44.263167',\n",
       "  'sst-2_dev_eval_loss': 0.2557363510131836,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-26422',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-26422/runs/Mar31_03-23-30_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-26422',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-26422',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Still*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 42,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:36:09.381378',\n",
       "  'sst-2_dev_eval_loss': 0.2245311588048935,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-30755',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-30755/runs/Mar31_03-29-51_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-30755',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-30755',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_This_is*mask*_stuff.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 43,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:42:35.975150',\n",
       "  'sst-2_dev_eval_loss': 0.2409987449645996,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-31621',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-31621/runs/Mar31_03-36-16_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-31621',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-31621',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_Its*mask*!*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 44,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:49:10.486677',\n",
       "  'sst-2_dev_eval_loss': 0.20493754744529724,\n",
       "  'sst-2_dev_eval_acc': 0.9621559633027523,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-20611',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-20611/runs/Mar31_03-42-43_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-20611',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-20611',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_show.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 45,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 03:55:38.836329',\n",
       "  'sst-2_dev_eval_loss': 0.20169170200824738,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-27070',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-27070/runs/Mar31_03-49-17_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-27070',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-27070',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_book.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 46,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:02:06.880624',\n",
       "  'sst-2_dev_eval_loss': 0.23259826004505157,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-10400',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-10400/runs/Mar31_03-55-46_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-10400',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-10400',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_The_result_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 47,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:08:33.722397',\n",
       "  'sst-2_dev_eval_loss': 0.2135884016752243,\n",
       "  'sst-2_dev_eval_acc': 0.9610091743119266,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-23140',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-23140/runs/Mar31_04-02-13_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-23140',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-23140',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_The_story_is*mask*.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 48,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:15:09.863474',\n",
       "  'sst-2_dev_eval_loss': 0.2393169105052948,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-2482',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-2482/runs/Mar31_04-08-40_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-2482',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-2482',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls**sent_0*_A*mask*_choice.*sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 49,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:21:52.454046',\n",
       "  'sst-2_dev_eval_loss': 0.20615550875663757,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12416',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12416/runs/Mar31_04-15-17_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12416',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12416',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls*_It's*mask*.*+sent_0**sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 50,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:28:16.932676',\n",
       "  'sst-2_dev_eval_loss': 0.1966775506734848,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12887',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12887/runs/Mar31_04-21-59_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12887',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12887',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_This_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 51,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:34:49.910316',\n",
       "  'sst-2_dev_eval_loss': 0.2819908559322357,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-22323',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-22323/runs/Mar31_04-28-24_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-22323',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-22323',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 52,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:41:13.296834',\n",
       "  'sst-2_dev_eval_loss': 0.24517647922039032,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-11864',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-11864/runs/Mar31_04-34-57_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-11864',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-11864',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_movie.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 53,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:47:36.683255',\n",
       "  'sst-2_dev_eval_loss': 0.22792798280715942,\n",
       "  'sst-2_dev_eval_acc': 0.9518348623853211,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-24372',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-24372/runs/Mar31_04-41-20_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-24372',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-24372',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Very*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 54,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 04:54:12.977921',\n",
       "  'sst-2_dev_eval_loss': 0.22149048745632172,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-19169',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-19169/runs/Mar31_04-47-44_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-19169',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-19169',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_film.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 55,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:00:46.100290',\n",
       "  'sst-2_dev_eval_loss': 0.22006601095199585,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-4353',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-4353/runs/Mar31_04-54-20_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-4353',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-4353',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It_was*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 56,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:07:14.817278',\n",
       "  'sst-2_dev_eval_loss': 0.24401208758354187,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-6113',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-6113/runs/Mar31_05-00-53_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-6113',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-6113',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Really*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 57,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:13:47.800678',\n",
       "  'sst-2_dev_eval_loss': 0.23085008561611176,\n",
       "  'sst-2_dev_eval_acc': 0.9610091743119266,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-22855',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-22855/runs/Mar31_05-07-21_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-22855',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-22855',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_story.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 58,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:20:15.479971',\n",
       "  'sst-2_dev_eval_loss': 0.21199427545070648,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-16755',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-16755/runs/Mar31_05-13-54_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-16755',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-16755',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Its*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 59,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:26:40.147455',\n",
       "  'sst-2_dev_eval_loss': 0.2081821709871292,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-10940',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-10940/runs/Mar31_05-20-22_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-10940',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-10940',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_So*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 60,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:33:12.197922',\n",
       "  'sst-2_dev_eval_loss': 0.20984968543052673,\n",
       "  'sst-2_dev_eval_acc': 0.963302752293578,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-26164',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-26164/runs/Mar31_05-26-47_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-26164',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-26164',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_This_is*mask*!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 61,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:39:44.661952',\n",
       "  'sst-2_dev_eval_loss': 0.23739534616470337,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-8203',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-8203/runs/Mar31_05-33-19_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-8203',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-8203',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls*_It's*mask*!*+sent_0**sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 62,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:46:03.083765',\n",
       "  'sst-2_dev_eval_loss': 0.2508746087551117,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-9567',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-9567/runs/Mar31_05-39-51_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-9567',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-9567',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Absolutely*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 63,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:52:23.296413',\n",
       "  'sst-2_dev_eval_loss': 0.20142917335033417,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-20410',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-20410/runs/Mar31_05-46-09_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-20410',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-20410',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*.*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 64,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 05:58:42.700927',\n",
       "  'sst-2_dev_eval_loss': 0.22651407122612,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-4961',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-4961/runs/Mar31_05-52-30_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-4961',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-4961',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Not*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 65,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:05:16.634975',\n",
       "  'sst-2_dev_eval_loss': 0.24256637692451477,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-13483',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-13483/runs/Mar31_05-58-50_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-13483',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-13483',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It’s*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 66,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:11:35.961777',\n",
       "  'sst-2_dev_eval_loss': 0.2572396397590637,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-694',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-694/runs/Mar31_06-05-23_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-694',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-694',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Just*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 67,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:17:52.243882',\n",
       "  'sst-2_dev_eval_loss': 0.22212550044059753,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-24552',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-24552/runs/Mar31_06-11-43_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-24552',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-24552',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 68,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:24:17.006238',\n",
       "  'sst-2_dev_eval_loss': 0.23676805198192596,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-17772',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-17772/runs/Mar31_06-17-59_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-17772',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-17772',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': \"*cls*_That's*mask*.*+sent_0**sep+*\",\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 69,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:30:50.698382',\n",
       "  'sst-2_dev_eval_loss': 0.25228649377822876,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-21329',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-21329/runs/Mar31_06-24-24_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-21329',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-21329',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It_is*mask*!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 70,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:37:14.478008',\n",
       "  'sst-2_dev_eval_loss': 0.2644672095775604,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-6365',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-6365/runs/Mar31_06-30-57_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-6365',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-6365',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_This_was*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 71,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:43:42.547868',\n",
       "  'sst-2_dev_eval_loss': 0.2177048772573471,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-25054',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-25054/runs/Mar31_06-37-21_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-25054',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-25054',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_The_film_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 72,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:50:13.484882',\n",
       "  'sst-2_dev_eval_loss': 0.24230754375457764,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-21572',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-21572/runs/Mar31_06-43-49_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-21572',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-21572',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 73,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 06:56:39.180777',\n",
       "  'sst-2_dev_eval_loss': 0.23510406911373138,\n",
       "  'sst-2_dev_eval_acc': 0.9518348623853211,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-25158',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-25158/runs/Mar31_06-50-21_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-25158',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-25158',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_experience.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 74,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:02:59.628092',\n",
       "  'sst-2_dev_eval_loss': 0.20828646421432495,\n",
       "  'sst-2_dev_eval_acc': 0.9644495412844036,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-32449',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-32449/runs/Mar31_06-56-46_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-32449',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-32449',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_That_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 75,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:09:26.344849',\n",
       "  'sst-2_dev_eval_loss': 0.2316116839647293,\n",
       "  'sst-2_dev_eval_acc': 0.9506880733944955,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-9944',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-9944/runs/Mar31_07-03-06_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-9944',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-9944',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_The*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 76,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:15:48.107886',\n",
       "  'sst-2_dev_eval_loss': 0.26161888241767883,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-2089',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-2089/runs/Mar31_07-09-33_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-2089',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-2089',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_one.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 77,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:22:13.298240',\n",
       "  'sst-2_dev_eval_loss': 0.24752938747406006,\n",
       "  'sst-2_dev_eval_acc': 0.9518348623853211,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-14240',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-14240/runs/Mar31_07-15-55_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-14240',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-14240',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Very*mask*!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 78,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:28:42.303935',\n",
       "  'sst-2_dev_eval_loss': 0.23811542987823486,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-27754',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-27754/runs/Mar31_07-22-20_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-27754',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-27754',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Still*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 79,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:35:08.141318',\n",
       "  'sst-2_dev_eval_loss': 0.23633652925491333,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-18776',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-18776/runs/Mar31_07-28-49_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-18776',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-18776',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It_looks*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 80,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:41:39.723906',\n",
       "  'sst-2_dev_eval_loss': 0.23589223623275757,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-3587',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-3587/runs/Mar31_07-35-14_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-3587',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-3587',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Pretty*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 81,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:48:03.177321',\n",
       "  'sst-2_dev_eval_loss': 0.24273593723773956,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-15939',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-15939/runs/Mar31_07-41-47_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-15939',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-15939',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_movie!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 82,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 07:54:31.891335',\n",
       "  'sst-2_dev_eval_loss': 0.2059110552072525,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-538',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-538/runs/Mar31_07-48-10_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-538',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-538',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_read.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 83,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:00:56.415645',\n",
       "  'sst-2_dev_eval_loss': 0.24524174630641937,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-19334',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-19334/runs/Mar31_07-54-39_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-19334',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-19334',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_All*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 84,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:07:23.594169',\n",
       "  'sst-2_dev_eval_loss': 0.2309887707233429,\n",
       "  'sst-2_dev_eval_acc': 0.9610091743119266,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-21128',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-21128/runs/Mar31_08-01-03_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-21128',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-21128',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_They_are*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 85,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:13:40.086133',\n",
       "  'sst-2_dev_eval_loss': 0.2567794620990753,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-28445',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-28445/runs/Mar31_08-07-31_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-28445',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-28445',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Looks*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 86,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:20:11.538563',\n",
       "  'sst-2_dev_eval_loss': 0.23328877985477448,\n",
       "  'sst-2_dev_eval_acc': 0.9575688073394495,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-21030',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-21030/runs/Mar31_08-13-47_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-21030',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-21030',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_The_movie_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 87,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:26:49.123666',\n",
       "  'sst-2_dev_eval_loss': 0.27735745906829834,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-19399',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-19399/runs/Mar31_08-20-18_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-19399',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-19399',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_So*mask*!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 88,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:33:16.108589',\n",
       "  'sst-2_dev_eval_loss': 0.22167415916919708,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-27474',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-27474/runs/Mar31_08-26-56_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-27474',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-27474',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_Sounds*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 89,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:39:41.418765',\n",
       "  'sst-2_dev_eval_loss': 0.24944037199020386,\n",
       "  'sst-2_dev_eval_acc': 0.9541284403669725,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-12947',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-12947/runs/Mar31_08-33-23_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-12947',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-12947',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_show.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 90,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:46:08.888856',\n",
       "  'sst-2_dev_eval_loss': 0.20102447271347046,\n",
       "  'sst-2_dev_eval_acc': 0.9529816513761468,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-15622',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-15622/runs/Mar31_08-39-48_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-15622',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-15622',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_And*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 91,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:52:37.154705',\n",
       "  'sst-2_dev_eval_loss': 0.21188120543956757,\n",
       "  'sst-2_dev_eval_acc': 0.9518348623853211,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-13493',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-13493/runs/Mar31_08-46-15_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-13493',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-13493',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_book.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 92,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 08:59:09.538623',\n",
       "  'sst-2_dev_eval_loss': 0.2093983292579651,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-20879',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-20879/runs/Mar31_08-52-44_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-20879',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-20879',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_film!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 93,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:05:34.869882',\n",
       "  'sst-2_dev_eval_loss': 0.21636401116847992,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-16329',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-16329/runs/Mar31_08-59-16_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-16329',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-16329',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_The_story_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 94,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:12:05.922077',\n",
       "  'sst-2_dev_eval_loss': 0.24162817001342773,\n",
       "  'sst-2_dev_eval_acc': 0.9587155963302753,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-5433',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-5433/runs/Mar31_09-05-42_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-5433',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-5433',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_It_was*mask*!*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 95,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:18:32.841643',\n",
       "  'sst-2_dev_eval_loss': 0.27528494596481323,\n",
       "  'sst-2_dev_eval_acc': 0.9552752293577982,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-24429',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-24429/runs/Mar31_09-12-12_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-24429',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-24429',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_thing.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 96,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:24:49.271096',\n",
       "  'sst-2_dev_eval_loss': 0.27841901779174805,\n",
       "  'sst-2_dev_eval_acc': 0.9564220183486238,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-25190',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-25190/runs/Mar31_09-18-39_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-25190',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-25190',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_This_film_is*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 97,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:31:17.558375',\n",
       "  'sst-2_dev_eval_loss': 0.19059088826179504,\n",
       "  'sst-2_dev_eval_acc': 0.9598623853211009,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-31729',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-31729/runs/Mar31_09-24-56_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-31729',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-31729',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_That_was*mask*.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 98,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None},\n",
       " {'time': '2022-03-31 09:37:48.248380',\n",
       "  'sst-2_dev_eval_loss': 0.3031211495399475,\n",
       "  'sst-2_dev_eval_acc': 0.9506880733944955,\n",
       "  'model_name_or_path': 'roberta-large',\n",
       "  'config_name': None,\n",
       "  'tokenizer_name': None,\n",
       "  'cache_dir': None,\n",
       "  'few_shot_type': 'prompt',\n",
       "  'random_segment': False,\n",
       "  'output_dir': 'result/SST-2-prompt-16-13-roberta-large-15266',\n",
       "  'overwrite_output_dir': True,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'per_device_train_batch_size': 2,\n",
       "  'per_device_eval_batch_size': 16,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'gradient_accumulation_steps': 4,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'learning_rate': 1e-05,\n",
       "  'weight_decay': 0.0,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'num_train_epochs': 0.0,\n",
       "  'max_steps': 1000,\n",
       "  'lr_scheduler_type': 'linear',\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 0,\n",
       "  'log_level': -1,\n",
       "  'log_level_replica': -1,\n",
       "  'log_on_each_node': True,\n",
       "  'logging_dir': 'result/SST-2-prompt-16-13-roberta-large-15266/runs/Mar31_09-31-24_eu-a65-02',\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 100,\n",
       "  'save_strategy': 'steps',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': None,\n",
       "  'save_on_each_node': False,\n",
       "  'no_cuda': False,\n",
       "  'seed': 13,\n",
       "  'fp16': False,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'fp16_backend': 'auto',\n",
       "  'fp16_full_eval': False,\n",
       "  'local_rank': -1,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': [],\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': 100,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'past_index': -1,\n",
       "  'run_name': 'result/SST-2-prompt-16-13-roberta-large-15266',\n",
       "  'disable_tqdm': False,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': False,\n",
       "  'metric_for_best_model': None,\n",
       "  'greater_is_better': None,\n",
       "  'ignore_data_skip': False,\n",
       "  'sharded_ddp': [],\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'adafactor': False,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'report_to': ['tensorboard'],\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'push_to_hub_model_id': 'SST-2-prompt-16-13-roberta-large-15266',\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'array_id': -1,\n",
       "  'model_id': -1,\n",
       "  'save_logit': False,\n",
       "  'save_logit_dir': None,\n",
       "  'fix_layers': 0,\n",
       "  'save_at_last': False,\n",
       "  'no_train': False,\n",
       "  'no_predict': True,\n",
       "  'evaluate_during_training': True,\n",
       "  '_n_gpu': 1,\n",
       "  '__cached__setup_devices': 'cuda:0',\n",
       "  'task_name': 'sst-2',\n",
       "  'data_dir': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13',\n",
       "  'max_seq_length': 128,\n",
       "  'overwrite_cache': False,\n",
       "  'num_k': 16,\n",
       "  'num_sample': 16,\n",
       "  'num_demo': 1,\n",
       "  'auto_demo': True,\n",
       "  'template': '*cls*_A*mask*_idea.*+sent_0**sep+*',\n",
       "  'mapping': \"{'0':'terrible','1':'great'}\",\n",
       "  'template_path': '/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt',\n",
       "  'mapping_path': None,\n",
       "  'prompt_path': None,\n",
       "  'template_id': 99,\n",
       "  'mapping_id': None,\n",
       "  'prompt_id': None,\n",
       "  'top_n_template': None,\n",
       "  'tag': 'exp-template',\n",
       "  'demo_filter': False,\n",
       "  'demo_filter_rate': 0.5,\n",
       "  'demo_filter_model': None,\n",
       "  'debug_mode': False,\n",
       "  'double_demo': False,\n",
       "  'first_sent_limit': None,\n",
       "  'other_sent_limit': None,\n",
       "  'use_full_length': None,\n",
       "  'gpt3_in_context_head': False,\n",
       "  'gpt3_in_context_tail': False,\n",
       "  'gpt3_in_context_num': 32,\n",
       "  'truncate_head': False,\n",
       "  'prompt': True,\n",
       "  'template_list': None}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cb32ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "line=line.replace(\"<SchedulerType.LINEAR: \\'linear\\'>\",\"\\\"linear\\\"\")\n",
    "line=line.replace(\"<IntervalStrategy.STEPS: \\'steps\\'>\",\"\\\"steps\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1cffbbf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'time\\': \\'2022-03-30 22:58:41.112672\\', \\'sst-2_dev_eval_loss\\': 0.2508125603199005, \\'sst-2_dev_eval_acc\\': 0.9598623853211009, \\'model_name_or_path\\': \\'roberta-large\\', \\'config_name\\': None, \\'tokenizer_name\\': None, \\'cache_dir\\': None, \\'few_shot_type\\': \\'prompt\\', \\'random_segment\\': False, \\'output_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-12083\\', \\'overwrite_output_dir\\': True, \\'do_train\\': True, \\'do_eval\\': True, \\'do_predict\\': False, \\'prediction_loss_only\\': False, \\'per_device_train_batch_size\\': 2, \\'per_device_eval_batch_size\\': 16, \\'per_gpu_train_batch_size\\': None, \\'per_gpu_eval_batch_size\\': None, \\'gradient_accumulation_steps\\': 4, \\'eval_accumulation_steps\\': None, \\'learning_rate\\': 1e-05, \\'weight_decay\\': 0.0, \\'adam_beta1\\': 0.9, \\'adam_beta2\\': 0.999, \\'adam_epsilon\\': 1e-08, \\'max_grad_norm\\': 1.0, \\'num_train_epochs\\': 0.0, \\'max_steps\\': 1000, \\'lr_scheduler_type\\': \"linear\", \\'warmup_ratio\\': 0.0, \\'warmup_steps\\': 0, \\'log_level\\': -1, \\'log_level_replica\\': -1, \\'log_on_each_node\\': True, \\'logging_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-12083/runs/Mar30_22-52-18_eu-a65-02\\', \\'logging_strategy\\': \"steps\", \\'logging_first_step\\': False, \\'logging_steps\\': 100, \\'save_strategy\\': \"steps\", \\'save_steps\\': 500, \\'save_total_limit\\': None, \\'save_on_each_node\\': False, \\'no_cuda\\': False, \\'seed\\': 13, \\'fp16\\': False, \\'fp16_opt_level\\': \\'O1\\', \\'fp16_backend\\': \\'auto\\', \\'fp16_full_eval\\': False, \\'local_rank\\': -1, \\'tpu_num_cores\\': None, \\'tpu_metrics_debug\\': False, \\'debug\\': [], \\'dataloader_drop_last\\': False, \\'eval_steps\\': 100, \\'dataloader_num_workers\\': 0, \\'past_index\\': -1, \\'run_name\\': \\'result/SST-2-prompt-16-13-roberta-large-12083\\', \\'disable_tqdm\\': False, \\'remove_unused_columns\\': True, \\'label_names\\': None, \\'load_best_model_at_end\\': False, \\'metric_for_best_model\\': None, \\'greater_is_better\\': None, \\'ignore_data_skip\\': False, \\'sharded_ddp\\': [], \\'deepspeed\\': None, \\'label_smoothing_factor\\': 0.0, \\'adafactor\\': False, \\'group_by_length\\': False, \\'length_column_name\\': \\'length\\', \\'report_to\\': [\\'tensorboard\\'], \\'ddp_find_unused_parameters\\': None, \\'dataloader_pin_memory\\': True, \\'skip_memory_metrics\\': True, \\'use_legacy_prediction_loop\\': False, \\'push_to_hub\\': False, \\'resume_from_checkpoint\\': None, \\'push_to_hub_model_id\\': \\'SST-2-prompt-16-13-roberta-large-12083\\', \\'push_to_hub_organization\\': None, \\'push_to_hub_token\\': None, \\'mp_parameters\\': \\'\\', \\'array_id\\': -1, \\'model_id\\': -1, \\'save_logit\\': False, \\'save_logit_dir\\': None, \\'fix_layers\\': 0, \\'save_at_last\\': False, \\'no_train\\': False, \\'no_predict\\': True, \\'evaluate_during_training\\': True, \\'_n_gpu\\': 1, \\'__cached__setup_devices\\': \"cuda:0\", \\'task_name\\': \\'sst-2\\', \\'data_dir\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13\\', \\'max_seq_length\\': 128, \\'overwrite_cache\\': False, \\'num_k\\': 16, \\'num_sample\\': 16, \\'num_demo\\': 1, \\'auto_demo\\': True, \\'template\\': \"*cls**sent_0*_It\\'s*mask*.*sep+*\", \\'mapping\\': \"{\\'0\\':\\'terrible\\',\\'1\\':\\'great\\'}\", \\'template_path\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt\\', \\'mapping_path\\': None, \\'prompt_path\\': None, \\'template_id\\': 0, \\'mapping_id\\': None, \\'prompt_id\\': None, \\'top_n_template\\': None, \\'tag\\': \\'exp-template\\', \\'demo_filter\\': False, \\'demo_filter_rate\\': 0.5, \\'demo_filter_model\\': None, \\'debug_mode\\': False, \\'double_demo\\': False, \\'first_sent_limit\\': None, \\'other_sent_limit\\': None, \\'use_full_length\\': None, \\'gpt3_in_context_head\\': False, \\'gpt3_in_context_tail\\': False, \\'gpt3_in_context_num\\': 32, \\'truncate_head\\': False, \\'prompt\\': True, \\'template_list\\': None}\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c8a49db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'time\\': \\'2022-03-30 21:26:05.012539\\', \\'sst-2_dev_eval_loss\\': 0.23619166016578674, \\'sst-2_dev_eval_acc\\': 0.9564220183486238, \\'model_name_or_path\\': \\'roberta-large\\', \\'config_name\\': None, \\'tokenizer_name\\': None, \\'cache_dir\\': None, \\'few_shot_type\\': \\'prompt\\', \\'random_segment\\': False, \\'output_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-4688\\', \\'overwrite_output_dir\\': True, \\'do_train\\': True, \\'do_eval\\': True, \\'do_predict\\': False, \\'prediction_loss_only\\': False, \\'per_device_train_batch_size\\': 2, \\'per_device_eval_batch_size\\': 16, \\'per_gpu_train_batch_size\\': None, \\'per_gpu_eval_batch_size\\': None, \\'gradient_accumulation_steps\\': 4, \\'eval_accumulation_steps\\': None, \\'learning_rate\\': 1e-05, \\'weight_decay\\': 0.0, \\'adam_beta1\\': 0.9, \\'adam_beta2\\': 0.999, \\'adam_epsilon\\': 1e-08, \\'max_grad_norm\\': 1.0, \\'num_train_epochs\\': 0.0, \\'max_steps\\': 1000, \\'lr_scheduler_type\\': \\'linear\\', \\'warmup_ratio\\': 0.0, \\'warmup_steps\\': 0, \\'log_level\\': -1, \\'log_level_replica\\': -1, \\'log_on_each_node\\': True, \\'logging_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-4688/runs/Mar30_21-16-13_eu-lo-dgx1-001\\', \\'logging_strategy\\':  \\'steps\\', \\'logging_first_step\\': False, \\'logging_steps\\': 100, \\'save_strategy\\': \\'steps\\', \\'save_steps\\': 500, \\'save_total_limit\\': None, \\'save_on_each_node\\': False, \\'no_cuda\\': False, \\'seed\\': 13, \\'fp16\\': False, \\'fp16_opt_level\\': \\'O1\\', \\'fp16_backend\\': \\'auto\\', \\'fp16_full_eval\\': False, \\'local_rank\\': -1, \\'tpu_num_cores\\': None, \\'tpu_metrics_debug\\': False, \\'debug\\': [], \\'dataloader_drop_last\\': False, \\'eval_steps\\': 100, \\'dataloader_num_workers\\': 0, \\'past_index\\': -1, \\'run_name\\': \\'result/SST-2-prompt-16-13-roberta-large-4688\\', \\'disable_tqdm\\': False, \\'remove_unused_columns\\': True, \\'label_names\\': None, \\'load_best_model_at_end\\': False, \\'metric_for_best_model\\': None, \\'greater_is_better\\': None, \\'ignore_data_skip\\': False, \\'sharded_ddp\\': [], \\'deepspeed\\': None, \\'label_smoothing_factor\\': 0.0, \\'adafactor\\': False, \\'group_by_length\\': False, \\'length_column_name\\': \\'length\\', \\'report_to\\': [\\'tensorboard\\'], \\'ddp_find_unused_parameters\\': None, \\'dataloader_pin_memory\\': True, \\'skip_memory_metrics\\': True, \\'use_legacy_prediction_loop\\': False, \\'push_to_hub\\': False, \\'resume_from_checkpoint\\': None, \\'push_to_hub_model_id\\': \\'SST-2-prompt-16-13-roberta-large-4688\\', \\'push_to_hub_organization\\': None, \\'push_to_hub_token\\': None, \\'mp_parameters\\': \\'\\', \\'array_id\\': -1, \\'model_id\\': -1, \\'save_logit\\': False, \\'save_logit_dir\\': None, \\'fix_layers\\': 0, \\'save_at_last\\': False, \\'no_train\\': False, \\'no_predict\\': True, \\'evaluate_during_training\\': True, \\'_n_gpu\\': 1, \\'__cached__setup_devices\\': \"cuda:0\", \\'task_name\\': \\'sst-2\\', \\'data_dir\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13\\', \\'max_seq_length\\': 128, \\'overwrite_cache\\': False, \\'num_k\\': 16, \\'num_sample\\': 16, \\'num_demo\\': 1, \\'auto_demo\\': True, \\'template\\': \"*cls**sent_0*_It\\'s*mask*.*sep+*\", \\'mapping\\': \"{\\'0\\':\\'terrible\\',\\'1\\':\\'great\\'}\", \\'template_path\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt\\', \\'mapping_path\\': None, \\'prompt_path\\': None, \\'template_id\\': 0, \\'mapping_id\\': None, \\'prompt_id\\': None, \\'top_n_template\\': None, \\'tag\\': \\'exp-template\\', \\'demo_filter\\': False, \\'demo_filter_rate\\': 0.5, \\'demo_filter_model\\': None, \\'debug_mode\\': False, \\'double_demo\\': False, \\'first_sent_limit\\': None, \\'other_sent_limit\\': None, \\'use_full_length\\': None, \\'gpt3_in_context_head\\': False, \\'gpt3_in_context_tail\\': False, \\'gpt3_in_context_num\\': 32, \\'truncate_head\\': False, \\'prompt\\': True, \\'template_list\\': None}\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.replace(\"device(type=\\'cuda\\', index=0)\",\"\\\"cuda:0\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bf910c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\'time\\': \\'2022-03-30 21:26:05.012539\\', \\'sst-2_dev_eval_loss\\': 0.23619166016578674, \\'sst-2_dev_eval_acc\\': 0.9564220183486238, \\'model_name_or_path\\': \\'roberta-large\\', \\'config_name\\': None, \\'tokenizer_name\\': None, \\'cache_dir\\': None, \\'few_shot_type\\': \\'prompt\\', \\'random_segment\\': False, \\'output_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-4688\\', \\'overwrite_output_dir\\': True, \\'do_train\\': True, \\'do_eval\\': True, \\'do_predict\\': False, \\'prediction_loss_only\\': False, \\'per_device_train_batch_size\\': 2, \\'per_device_eval_batch_size\\': 16, \\'per_gpu_train_batch_size\\': None, \\'per_gpu_eval_batch_size\\': None, \\'gradient_accumulation_steps\\': 4, \\'eval_accumulation_steps\\': None, \\'learning_rate\\': 1e-05, \\'weight_decay\\': 0.0, \\'adam_beta1\\': 0.9, \\'adam_beta2\\': 0.999, \\'adam_epsilon\\': 1e-08, \\'max_grad_norm\\': 1.0, \\'num_train_epochs\\': 0.0, \\'max_steps\\': 1000, \\'lr_scheduler_type\\': \\'linear\\', \\'warmup_ratio\\': 0.0, \\'warmup_steps\\': 0, \\'log_level\\': -1, \\'log_level_replica\\': -1, \\'log_on_each_node\\': True, \\'logging_dir\\': \\'result/SST-2-prompt-16-13-roberta-large-4688/runs/Mar30_21-16-13_eu-lo-dgx1-001\\', \\'logging_strategy\\':  \\'steps\\', \\'logging_first_step\\': False, \\'logging_steps\\': 100, \\'save_strategy\\': \\'steps\\', \\'save_steps\\': 500, \\'save_total_limit\\': None, \\'save_on_each_node\\': False, \\'no_cuda\\': False, \\'seed\\': 13, \\'fp16\\': False, \\'fp16_opt_level\\': \\'O1\\', \\'fp16_backend\\': \\'auto\\', \\'fp16_full_eval\\': False, \\'local_rank\\': -1, \\'tpu_num_cores\\': None, \\'tpu_metrics_debug\\': False, \\'debug\\': [], \\'dataloader_drop_last\\': False, \\'eval_steps\\': 100, \\'dataloader_num_workers\\': 0, \\'past_index\\': -1, \\'run_name\\': \\'result/SST-2-prompt-16-13-roberta-large-4688\\', \\'disable_tqdm\\': False, \\'remove_unused_columns\\': True, \\'label_names\\': None, \\'load_best_model_at_end\\': False, \\'metric_for_best_model\\': None, \\'greater_is_better\\': None, \\'ignore_data_skip\\': False, \\'sharded_ddp\\': [], \\'deepspeed\\': None, \\'label_smoothing_factor\\': 0.0, \\'adafactor\\': False, \\'group_by_length\\': False, \\'length_column_name\\': \\'length\\', \\'report_to\\': [\\'tensorboard\\'], \\'ddp_find_unused_parameters\\': None, \\'dataloader_pin_memory\\': True, \\'skip_memory_metrics\\': True, \\'use_legacy_prediction_loop\\': False, \\'push_to_hub\\': False, \\'resume_from_checkpoint\\': None, \\'push_to_hub_model_id\\': \\'SST-2-prompt-16-13-roberta-large-4688\\', \\'push_to_hub_organization\\': None, \\'push_to_hub_token\\': None, \\'mp_parameters\\': \\'\\', \\'array_id\\': -1, \\'model_id\\': -1, \\'save_logit\\': False, \\'save_logit_dir\\': None, \\'fix_layers\\': 0, \\'save_at_last\\': False, \\'no_train\\': False, \\'no_predict\\': True, \\'evaluate_during_training\\': True, \\'_n_gpu\\': 1, \\'__cached__setup_devices\\': device(type=\\'cuda\\', index=0), \\'task_name\\': \\'sst-2\\', \\'data_dir\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13\\', \\'max_seq_length\\': 128, \\'overwrite_cache\\': False, \\'num_k\\': 16, \\'num_sample\\': 16, \\'num_demo\\': 1, \\'auto_demo\\': True, \\'template\\': \"*cls**sent_0*_It\\'s*mask*.*sep+*\", \\'mapping\\': \"{\\'0\\':\\'terrible\\',\\'1\\':\\'great\\'}\", \\'template_path\\': \\'/cluster/scratch/fgonzalez/auto_template/SST-2/16-13.txt\\', \\'mapping_path\\': None, \\'prompt_path\\': None, \\'template_id\\': 0, \\'mapping_id\\': None, \\'prompt_id\\': None, \\'top_n_template\\': None, \\'tag\\': \\'exp-template\\', \\'demo_filter\\': False, \\'demo_filter_rate\\': 0.5, \\'demo_filter_model\\': None, \\'debug_mode\\': False, \\'double_demo\\': False, \\'first_sent_limit\\': None, \\'other_sent_limit\\': None, \\'use_full_length\\': None, \\'gpt3_in_context_head\\': False, \\'gpt3_in_context_tail\\': False, \\'gpt3_in_context_num\\': 32, \\'truncate_head\\': False, \\'prompt\\': True, \\'template_list\\': None}\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04ebb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "parser = HfArgumentParser((ModelArguments, DynamicDataTrainingArguments, DynamicTrainingArguments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if len(sys.argv) == 2 and sys.argv[1].endswith(\".json\"):\n",
    "    # If we pass only one argument to the script and it's the path to a json file,\n",
    "    # let's parse it to get our arguments.\n",
    "    model_args, data_args, training_args = parser.parse_json_file(json_file=os.path.abspath(sys.argv[1]))\n",
    "else:\n",
    "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1f690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d868ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143996db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some specified arguments are not used by the HfArgumentParser: ['-f', '/cluster/home/fgonzalez/.local/share/jupyter/runtime/kernel-b2f2dd87-4a5e-46a9-908b-40dc54c93546.json', 'task_name', 'path1', 'data_dir', 'path2', 'output_dir', 'path3']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch/211899364.tmpdir/ipykernel_50294/2051728458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args_into_dataclasses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/scirex/lib64/python3.7/site-packages/transformers/hf_argparser.py\u001b[0m in \u001b[0;36mparse_args_into_dataclasses\u001b[0;34m(self, args, return_remaining_strings, look_for_args_file, args_filename)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Some specified arguments are not used by the HfArgumentParser: {remaining_args}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Some specified arguments are not used by the HfArgumentParser: ['-f', '/cluster/home/fgonzalez/.local/share/jupyter/runtime/kernel-b2f2dd87-4a5e-46a9-908b-40dc54c93546.json', 'task_name', 'path1', 'data_dir', 'path2', 'output_dir', 'path3']"
     ]
    }
   ],
   "source": [
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fefa743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/cluster/home/fgonzalez/.virtualenvs/scirex/lib64/python3.7/site-packages/ipykernel_launcher.py',\n",
       " '-f',\n",
       " '/cluster/home/fgonzalez/.local/share/jupyter/runtime/kernel-b2f2dd87-4a5e-46a9-908b-40dc54c93546.json',\n",
       " '--model_name_or_path']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c840a282",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --model_name_or_path: conflicting option string: --model_name_or_path",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/scratch/211899364.tmpdir/ipykernel_50294/295072610.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--model_name_or_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--task_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--data_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--output_dir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \u001b[0;31m# resolve any conflicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# add to actions list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0mconflict_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                                      \u001b[0;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m                                      in conflicting_actions])\n\u001b[0;32m-> 1529\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --model_name_or_path: conflicting option string: --model_name_or_path"
     ]
    }
   ],
   "source": [
    "parser.add_argument('--model_name_or_path', type=int, default=4)\n",
    "parser.add_argument('--task_name', type=int, default=4)\n",
    "parser.add_argument('--data_dir', type=int, default=4)\n",
    "parser.add_argument('--output_dir', type=int, default=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "-model_name_or_path, --task_name, --data_dir, --output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99234508",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'line' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/211899364.tmpdir/ipykernel_50294/1298077829.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'line' is not defined"
     ]
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396faa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 'prompt' in model_args.few_shot_type:\n",
    "    data_args.prompt = True\n",
    "\n",
    "if training_args.no_train:\n",
    "    training_args.do_train = False\n",
    "if training_args.no_predict:\n",
    "    training_args.do_predict = False\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "\n",
    "# Load prompt/template/mapping file\n",
    "if data_args.prompt:\n",
    "    if data_args.prompt_path is not None:\n",
    "        assert data_args.prompt_id is not None\n",
    "        prompt_list = []\n",
    "        with open(data_args.prompt_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                template, mapping = line.split('\\t')\n",
    "                prompt_list.append((template, mapping))\n",
    "\n",
    "        data_args.template, data_args.mapping = prompt_list[data_args.prompt_id] \n",
    "        logger.info(\"Specify load the %d-th prompt: %s | %s\" % (data_args.prompt_id, data_args.template, data_args.mapping))\n",
    "    else:\n",
    "        if data_args.template_path is not None:\n",
    "            with open(data_args.template_path) as f:\n",
    "                data_args.template_list = []\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if len(line) > 0:\n",
    "                        data_args.template_list.append(line)\n",
    "\n",
    "            # Load top-n templates\n",
    "            if data_args.top_n_template is not None:\n",
    "                data_args.template_list = data_args.template_list[:data_args.top_n_template]\n",
    "            logger.info(\"Load top-%d templates from %s\" % (len(data_args.template_list), data_args.template_path))\n",
    "\n",
    "            # ... or load i-th template\n",
    "            if data_args.template_id is not None:\n",
    "                data_args.template = data_args.template_list[data_args.template_id]\n",
    "                data_args.template_list = None\n",
    "                logger.info(\"Specify load the %d-th template: %s\" % (data_args.template_id, data_args.template))\n",
    "\n",
    "        if data_args.mapping_path is not None:\n",
    "            assert data_args.mapping_id is not None # Only can use one label word mapping\n",
    "            with open(data_args.mapping_path) as f:\n",
    "                mapping_list = []\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    mapping_list.append(line)\n",
    "\n",
    "            data_args.mapping = mapping_list[data_args.mapping_id]\n",
    "            logger.info(\"Specify using the %d-th mapping: %s\" % (data_args.mapping_id, data_args.mapping))\n",
    "\n",
    "# Check save path\n",
    "if (\n",
    "    os.path.exists(training_args.output_dir)\n",
    "    and os.listdir(training_args.output_dir)\n",
    "    and training_args.do_train\n",
    "    and not training_args.overwrite_output_dir\n",
    "):\n",
    "    raise ValueError(f\"Output directory ({training_args.output_dir}) already exists.\")\n",
    "\n",
    "logger.warning(\n",
    "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
    "    training_args.local_rank,\n",
    "    training_args.device,\n",
    "    training_args.n_gpu,\n",
    "    bool(training_args.local_rank != -1),\n",
    "    training_args.fp16,\n",
    ")\n",
    "logger.info(\"Training/evaluation parameters %s\", training_args)\n",
    "\n",
    "# Set seed\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "try:\n",
    "    num_labels = num_labels_mapping[data_args.task_name]\n",
    "    output_mode = output_modes_mapping[data_args.task_name]\n",
    "    logger.info(\"Task name: {}, number of labels: {}, output mode: {}\".format(data_args.task_name, num_labels, output_mode))\n",
    "except KeyError:\n",
    "    raise ValueError(\"Task not found: %s\" % (data_args.task_name))\n",
    "\n",
    "# Automatically generate template for using demonstrations\n",
    "if data_args.auto_demo and model_args.few_shot_type == 'prompt-demo':\n",
    "    # GPT-3's in-context learning\n",
    "    if data_args.gpt3_in_context_head or data_args.gpt3_in_context_tail: \n",
    "        logger.info(\"Automatically convert the template to GPT-3's in-context learning.\")\n",
    "        assert data_args.template_list is None\n",
    "\n",
    "        old_template = data_args.template\n",
    "        new_template = old_template + ''\n",
    "        old_template = old_template.replace('*cls*', '')\n",
    "        # Single sentence or sentence pair?\n",
    "        sent_num = 1\n",
    "        if \"_1\" in old_template:\n",
    "            sent_num = 2\n",
    "        for instance_id in range(data_args.gpt3_in_context_num):\n",
    "            sub_template = old_template + ''\n",
    "            # Replace sent_id\n",
    "            for sent_id in range(sent_num):\n",
    "                sub_template = sub_template.replace(\"_{}*\".format(sent_id), \"_{}*\".format(sent_num + sent_num * instance_id + sent_id))\n",
    "            # Replace mask\n",
    "            sub_template = sub_template.replace(\"*mask*\", \"*labelx_{}*\".format(instance_id))\n",
    "            if data_args.gpt3_in_context_tail:\n",
    "                new_template = new_template + sub_template # Put context at the end\n",
    "            else:\n",
    "                new_template = sub_template + new_template # Put context at the beginning\n",
    "        logger.info(\"| {} => {}\".format(data_args.template, new_template))\n",
    "        data_args.template = new_template\n",
    "    else:\n",
    "        logger.info(\"Automatically convert the template to using demonstrations.\")\n",
    "        if data_args.template_list is not None:\n",
    "            for i in range(len(data_args.template_list)):\n",
    "                old_template = data_args.template_list[i]\n",
    "                new_template = old_template + ''\n",
    "                old_template = old_template.replace('*cls*', '')\n",
    "                # Single sentence or sentence pair?\n",
    "                sent_num = 1\n",
    "                if \"_1\" in old_template:\n",
    "                    sent_num = 2\n",
    "                for label_id in range(num_labels):\n",
    "                    sub_template = old_template + ''\n",
    "                    # Replace sent id\n",
    "                    for sent_id in range(sent_num):\n",
    "                        sub_template = sub_template.replace(\"_{}*\".format(sent_id), \"_{}*\".format(sent_num + sent_num * label_id + sent_id))\n",
    "                    # Replace mask\n",
    "                    sub_template = sub_template.replace(\"*mask*\", \"*label_{}*\".format(label_id))\n",
    "                    new_template = new_template + sub_template\n",
    "                logger.info(\"| {} => {}\".format(data_args.template_list[i], new_template))\n",
    "                data_args.template_list[i] = new_template\n",
    "        else:\n",
    "            old_template = data_args.template\n",
    "            new_template = old_template + ''\n",
    "            old_template = old_template.replace('*cls*', '')\n",
    "            # Single sentence or sentence pair?\n",
    "            sent_num = 1\n",
    "            if \"_1\" in old_template:\n",
    "                sent_num = 2\n",
    "            for label_id in range(num_labels):\n",
    "                sub_template = old_template + ''\n",
    "                # Replace sent id\n",
    "                for sent_id in range(sent_num):\n",
    "                    sub_template = sub_template.replace(\"_{}\".format(sent_id), \"_{}\".format(sent_num + sent_num * label_id + sent_id))\n",
    "                # Replace mask\n",
    "                sub_template = sub_template.replace(\"*mask*\", \"*label_{}*\".format(label_id))\n",
    "                new_template = new_template + sub_template\n",
    "            logger.info(\"| {} => {}\".format(data_args.template, new_template))\n",
    "            data_args.template = new_template\n",
    "\n",
    "# Create config\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=data_args.task_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "if 'prompt' in model_args.few_shot_type:\n",
    "    if config.model_type == 'roberta':\n",
    "        model_fn = RobertaForPromptFinetuning\n",
    "    elif config.model_type == 'bert':\n",
    "        model_fn = BertForPromptFinetuning\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "elif model_args.few_shot_type == 'finetune':\n",
    "    model_fn = AutoModelForSequenceClassification\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "special_tokens = []\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    additional_special_tokens=special_tokens,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "# Get our special datasets.\n",
    "train_dataset = (\n",
    "    FewShotDataset(data_args, tokenizer=tokenizer, mode=\"train\", use_demo=(\"demo\" in model_args.few_shot_type))\n",
    ")\n",
    "eval_dataset = (\n",
    "    FewShotDataset(data_args, tokenizer=tokenizer, mode=\"dev\", use_demo=(\"demo\" in model_args.few_shot_type))\n",
    "    if training_args.do_eval\n",
    "    else None\n",
    ")\n",
    "test_dataset = (\n",
    "    FewShotDataset(data_args, tokenizer=tokenizer, mode=\"test\", use_demo=(\"demo\" in model_args.few_shot_type))\n",
    "    if training_args.do_predict\n",
    "    else None\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "model = model_fn.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")\n",
    "\n",
    "# For BERT, increase the size of the segment (token type) embeddings\n",
    "if config.model_type == 'bert':\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    resize_token_type_embeddings(model, new_num_types=10, random_segment=model_args.random_segment)\n",
    "\n",
    "# Pass dataset and argument information to the model\n",
    "if data_args.prompt:\n",
    "    model.label_word_list = torch.tensor(train_dataset.label_word_list).long().cuda()\n",
    "if output_modes_mapping[data_args.task_name] == 'regression':\n",
    "    # lower / upper bounds\n",
    "    model.lb, model.ub = bound_mapping[data_args.task_name]\n",
    "model.model_args = model_args\n",
    "model.data_args = data_args\n",
    "model.tokenizer = tokenizer\n",
    "\n",
    "# Build metric\n",
    "def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
    "    def compute_metrics_fn(p: EvalPrediction):\n",
    "        # Note: the eval dataloader is sequential, so the examples are in order.\n",
    "        # We average the logits over each sample for using demonstrations.\n",
    "        predictions = p.predictions\n",
    "        num_logits = predictions.shape[-1]\n",
    "        logits = predictions.reshape([eval_dataset.num_sample, -1, num_logits])\n",
    "        logits = logits.mean(axis=0)\n",
    "\n",
    "        if num_logits == 1:\n",
    "            preds = np.squeeze(logits)\n",
    "        else:\n",
    "            preds = np.argmax(logits, axis=1)\n",
    "\n",
    "        # Just for sanity, assert label ids are the same.\n",
    "        label_ids = p.label_ids.reshape([eval_dataset.num_sample, -1])\n",
    "        label_ids_avg = label_ids.mean(axis=0)\n",
    "        label_ids_avg = label_ids_avg.astype(p.label_ids.dtype)\n",
    "        assert (label_ids_avg - label_ids[0]).mean() < 1e-2\n",
    "        label_ids = label_ids[0]\n",
    "\n",
    "        return compute_metrics_mapping[task_name](task_name, preds, label_ids)\n",
    "\n",
    "    return compute_metrics_fn\n",
    "\n",
    "# Initialize our Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=build_compute_metrics_fn(data_args.task_name)\n",
    ")\n",
    "\n",
    "# Training\n",
    "if training_args.do_train:\n",
    "    trainer.train(model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None)\n",
    "    # Use the early stop, so do not save the model in the end (unless specify save_at_last)\n",
    "    if training_args.save_at_last:\n",
    "        trainer.save_model(training_args.output_dir)\n",
    "\n",
    "    if trainer.is_world_process_zero():\n",
    "        tokenizer.save_pretrained(training_args.output_dir)\n",
    "        torch.save(model_args, os.path.join(training_args.output_dir, \"model_args.bin\"))\n",
    "        torch.save(data_args, os.path.join(training_args.output_dir, \"data_args.bin\"))\n",
    "\n",
    "    # Reload the best checkpoint (for eval)\n",
    "    model = model_fn.from_pretrained(training_args.output_dir)\n",
    "    model = model.to(training_args.device)\n",
    "    trainer.model = model\n",
    "    if data_args.prompt:\n",
    "        model.label_word_list = torch.tensor(train_dataset.label_word_list).long().cuda()\n",
    "    if output_modes_mapping[data_args.task_name] == 'regression':\n",
    "        # lower / upper bounds\n",
    "        model.lb, model.ub = bound_mapping[data_args.task_name]\n",
    "    model.model_args = model_args\n",
    "    model.data_args = data_args\n",
    "    model.tokenizer = tokenizer\n",
    "\n",
    "# Evaluation\n",
    "final_result = {\n",
    "    'time': str(datetime.today()),\n",
    "}\n",
    "\n",
    "eval_results = {}\n",
    "if training_args.do_eval:\n",
    "    logger.info(\"*** Validate ***\")\n",
    "\n",
    "    eval_datasets = [eval_dataset]\n",
    "\n",
    "    for eval_dataset in eval_datasets:\n",
    "        trainer.compute_metrics = build_compute_metrics_fn(eval_dataset.args.task_name)\n",
    "        output = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "        eval_result = output.metrics \n",
    "\n",
    "        output_eval_file = os.path.join(\n",
    "            training_args.output_dir, f\"eval_results_{eval_dataset.args.task_name}.txt\"\n",
    "        )\n",
    "        if trainer.is_world_process_zero():\n",
    "            with open(output_eval_file, \"w\") as writer:\n",
    "                logger.info(\"***** Eval results {} *****\".format(eval_dataset.args.task_name))\n",
    "                for key, value in eval_result.items():\n",
    "                    logger.info(\"  %s = %s\", key, value)\n",
    "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
    "                    final_result[eval_dataset.args.task_name + '_dev_' + key] = value\n",
    "        eval_results.update(eval_result)\n",
    "\n",
    "test_results = {}\n",
    "if training_args.do_predict:\n",
    "    logging.info(\"*** Test ***\")\n",
    "    test_datasets = [test_dataset]\n",
    "    if data_args.task_name == \"mnli\":\n",
    "        mnli_mm_data_args = dataclasses.replace(data_args, task_name=\"mnli-mm\")\n",
    "        test_datasets.append(\n",
    "            FewShotDataset(mnli_mm_data_args, tokenizer=tokenizer, mode=\"test\", use_demo=('demo' in model_args.few_shot_type))\n",
    "        )\n",
    "\n",
    "    for test_dataset in test_datasets:\n",
    "        trainer.compute_metrics = build_compute_metrics_fn(test_dataset.args.task_name)\n",
    "        output = trainer.evaluate(eval_dataset=test_dataset)\n",
    "        test_result = output.metrics\n",
    "\n",
    "        output_test_file = os.path.join(\n",
    "            training_args.output_dir, f\"test_results_{test_dataset.args.task_name}.txt\"\n",
    "        )\n",
    "        if trainer.is_world_process_zero():\n",
    "            with open(output_test_file, \"w\") as writer:\n",
    "                logger.info(\"***** Test results {} *****\".format(test_dataset.args.task_name))\n",
    "                for key, value in test_result.items():\n",
    "                    logger.info(\"  %s = %s\", key, value)\n",
    "                    writer.write(\"%s = %s\\n\" % (key, value))\n",
    "                    final_result[test_dataset.args.task_name + '_test_' + key] = value\n",
    "\n",
    "            if training_args.save_logit:\n",
    "                predictions = output.predictions\n",
    "                num_logits = predictions.shape[-1]\n",
    "                logits = predictions.reshape([test_dataset.num_sample, -1, num_logits]).mean(axis=0)\n",
    "                np.save(os.path.join(training_args.save_logit_dir, \"{}-{}-{}.npy\".format(test_dataset.task_name, training_args.model_id, training_args.array_id)), logits)\n",
    "\n",
    "        test_results.update(test_result)\n",
    "\n",
    "with FileLock('log.lock'):\n",
    "    with open('log', 'a') as f:\n",
    "        final_result.update(vars(model_args))\n",
    "        final_result.update(vars(training_args))\n",
    "        final_result.update(vars(data_args))\n",
    "        if 'evaluation_strategy' in final_result:\n",
    "            final_result.pop('evaluation_strategy')\n",
    "        f.write(str(final_result) + '\\n')\n",
    "\n",
    "return eval_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9212d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
